{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Proect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean up comments dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import string, re, pickle\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, log_loss\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download annotated comments and annotations\n",
    "import requests\n",
    "\n",
    "ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7554634' \n",
    "ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7554637' \n",
    "\n",
    "ANNOTATED_COMMENTS = requests.get(ANNOTATED_COMMENTS_URL, allow_redirects=True)\n",
    "ANNOTATIONS = requests.get(ANNOTATIONS_URL, allow_redirects=True)\n",
    "\n",
    "open('dataset/attack_annotated_comments.tsv', 'wb').write(ANNOTATED_COMMENTS.content)\n",
    "open('dataset/attack_annotations.tsv', 'wb').write(ANNOTATIONS.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('dataset/attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations = pd.read_csv('dataset/attack_annotations.tsv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115864"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations['rev_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels a comment as an atack if the majority of annoatators did so\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rev_id\n",
       "594271742    False\n",
       "437509203    False\n",
       "28516703     False\n",
       "Name: attack, dtype: bool"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join labels and comments\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>.`=/?@#$%^&*_~'''\n",
    "    no_punct = \"\"\n",
    "    for char in text:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "    return no_punct\n",
    "\n",
    "\n",
    "def word_list(doc):\n",
    "    wordlist = []\n",
    "    for r in doc:\n",
    "        for x in r.split():\n",
    "            wordlist.append(x)\n",
    "    return wordlist\n",
    "\n",
    "def word_fre(wordlist):\n",
    "    word_freq = {}\n",
    "    for word in wordlist:\n",
    "        if word not in word_freq:\n",
    "            word_freq[word] = 0\n",
    "        word_freq[word] += 1\n",
    "    return word_freq\n",
    "\n",
    "def find_top_high_freq_words():\n",
    "    wordlist = word_list(comments.comment.tolist())\n",
    "    wordfreq = word_fre(wordlist)\n",
    "    sort_freq = sorted(wordfreq.items(), key=operator.itemgetter(1))\n",
    "    return sort_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_freq = find_top_high_freq_words()\n",
    "stop = [x[0] for x in sort_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stop[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove newline and tab tokens\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "\n",
    "# Removing multiple whitespaces\n",
    "comments['comment'] = comments['comment'].apply(lambda x: re.sub(r\"\\?\", \" \\? \", x))\n",
    "\n",
    "# Remove numbers\n",
    "comments['comment'] = comments['comment'].apply(lambda x: re.sub(r\"[0-9]+\", \"\", x))\n",
    "# lower case\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.lower())\n",
    "# remove all punctuation\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(string.punctuation, \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: remove_punctuation(x))\n",
    "\n",
    "\n",
    "# Removing multiple whitespaces\n",
    "comments['comment'] = comments['comment'].apply(lambda x: re.sub(r\"\\?\", \" \\? \", x))\n",
    "\n",
    "# remove URL\n",
    "comments['comment'] = comments['comment'].apply(lambda x: re.sub(r'^https?:\\/\\/.*[\\r\\n]*', \"\", x, flags=re.MULTILINE))\n",
    "\n",
    "\n",
    "# remove english stop words\n",
    "# new_comment = []\n",
    "# for index, row in comments.iterrows():\n",
    "#     words = [w for w in row['comment'].split() if not w in stop_words]\n",
    "#     new_comment.append(' '.join(words))\n",
    "# comments['comment'] = new_comment\n",
    "\n",
    "comments = comments.replace(np.nan, '', regex=True)\n",
    "# Removing multiple whitespaces\n",
    "comments['comment'] = comments['comment'].apply(lambda x: re.sub(r\"\\?\", \" \\? \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dataset/clearn_up_comments.pickle', 'wb') as f:\n",
    "#     pickle.dump(comments, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dataset/clearn_up_comments.pickle', 'rb') as f:\n",
    "#     comments = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment      115864\n",
       "year         115864\n",
       "logged_in    115864\n",
       "ns           115864\n",
       "sample       115864\n",
       "split        115864\n",
       "attack       115864\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224891827</th>\n",
       "      <td>no its a secret project with no confirmation...</td>\n",
       "      <td>2008</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662882399</th>\n",
       "      <td>rfa   please dont badger opposers of an rfa...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230723384</th>\n",
       "      <td>unblock| oxymoron is a moron in an oxymoron ...</td>\n",
       "      <td>2008</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330174799</th>\n",
       "      <td>birthday note   a little late on my part bu...</td>\n",
       "      <td>2009</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138838973</th>\n",
       "      <td>and  you should note that i am not wrong tha...</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     comment  year  logged_in  \\\n",
       "rev_id                                                                          \n",
       "224891827    no its a secret project with no confirmation...  2008      False   \n",
       "662882399     rfa   please dont badger opposers of an rfa...  2015       True   \n",
       "230723384    unblock| oxymoron is a moron in an oxymoron ...  2008      False   \n",
       "330174799     birthday note   a little late on my part bu...  2009       True   \n",
       "138838973    and  you should note that i am not wrong tha...  2007       True   \n",
       "\n",
       "                ns   sample  split  attack  \n",
       "rev_id                                      \n",
       "224891827  article  blocked   test   False  \n",
       "662882399     user  blocked   test   False  \n",
       "230723384     user  blocked  train    True  \n",
       "330174799     user   random   test   False  \n",
       "138838973     user  blocked    dev   False  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11107"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query with boolean expression\n",
    "comments.query('attack')['logged_in'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment      30946\n",
      "year         30946\n",
      "logged_in    30946\n",
      "ns           30946\n",
      "sample       30946\n",
      "split        30946\n",
      "attack       30946\n",
      "dtype: int64\n",
      "comment      11107\n",
      "year         11107\n",
      "logged_in    11107\n",
      "ns           11107\n",
      "sample       11107\n",
      "split        11107\n",
      "attack       11107\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "logout = comments[comments.logged_in == False]\n",
    "print(logout.count())\n",
    "out_a = comments[comments.attack == True]\n",
    "print(out_a.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a6a1a2550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attack_level = comments['attack'].value_counts()\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(attack_level.index, attack_level.values, alpha=0.8, color=color[0])\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Attack', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c2c9320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "years = comments.query('attack').groupby('year').count()\n",
    "years = years.attack\n",
    "plt.figure(figsize=(50,10))\n",
    "sns.barplot(years.index, years.values, alpha=0.8, color=color[0])\n",
    "plt.ylabel('Number of attacks', fontsize=12)\n",
    "plt.xlabel('Years', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comments = comments.query(\"split=='train'\")\n",
    "dev_comments = comments.query(\"split=='dev'\")\n",
    "test_comments = comments.query(\"split=='test'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of rev_id, year, logged_in, ns, sample column that will not be used in training\n",
    "# only keep comments as training feature\n",
    "def get_X_Y(data):\n",
    "    X = data.comment\n",
    "    Y = data.iloc[:, -1]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = get_X_Y(train_comments)\n",
    "X_dev, Y_dev = get_X_Y(dev_comments)\n",
    "X_test, Y_test = get_X_Y(test_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rev_id\n",
       "241552424      joseph stalin please stop adding unsourced n...\n",
       "385983088                         a user you banned i assume  \n",
       "61108043     there should be a note about criticism of the ...\n",
       "321655093                           sorry i dont speek spanish\n",
       "295520884     im sorry but that would be utterly retarded  ...\n",
       "627057148     im only looking for some help thats it nothin...\n",
       "437012137      update on opposition parties  httpwwwbbccouk...\n",
       "96481950      even look at marty sertichs wiki page  high s...\n",
       "253175145     further to this it would be appeciated if you...\n",
       "182692555      another movie sleep easy hutch rimes was als...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.966\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.95      0.99      0.97     20913\n",
      "       True       0.92      0.55      0.69      2265\n",
      "\n",
      "avg / total       0.95      0.95      0.95     23178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a simple text classifier\n",
    "lr_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='word', max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "lr_clf = lr_clf.fit(X_train, Y_train)\n",
    "auc = roc_auc_score(Y_test, lr_clf.predict_proba(X_test)[:, 1])\n",
    "print('Test ROC AUC: %.3f' %auc)\n",
    "predicted = lr_clf.predict(X_test)\n",
    "print(metrics.classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameter tuning\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000)),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', LogisticRegression(n_jobs=-1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': [1.0, 5.0],\n",
      " 'clf__max_iter': [100, 150],\n",
      " 'clf__penalty': ['l1', 'l2']}\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "           \"clf__penalty\" : ['l1', 'l2'],\n",
    "           \"clf__C\" : [1.0, 5.0],\n",
    "           \"clf__max_iter\" : [100, 150]}\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/Users/xiaofan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=10000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        stri...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__penalty': ['l1', 'l2'], 'clf__C': [1.0, 5.0], 'clf__max_iter': [100, 150]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs_clf = GridSearchCV(estimator=text_clf, param_grid=param_grid, n_jobs=-1)\n",
    "gs_clf.fit(train_comments['comment'], train_comments['attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954693208296\n",
      "clf__C: 1.0\n",
      "clf__max_iter: 100\n",
      "clf__penalty: 'l1'\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf.best_score_)\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.946\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.95      0.99      0.97     20913\n",
      "       True       0.87      0.52      0.65      2265\n",
      "\n",
      "avg / total       0.94      0.95      0.94     23178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='word', max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "mnb = mnb.fit(X_train, Y_train)\n",
    "auc = roc_auc_score(Y_test, mnb.predict_proba(X_test)[:, 1])\n",
    "print('Test ROC AUC: %.3f' %auc)\n",
    "predicted = mnb.predict(X_test)\n",
    "print(metrics.classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.934\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.95      0.99      0.97     20913\n",
      "       True       0.90      0.53      0.66      2265\n",
      "\n",
      "avg / total       0.95      0.95      0.94     23178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='word', max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', RandomForestClassifier(n_estimators=20,\n",
    "#                                    max_features='sqrt', \n",
    "#                                    min_samples_leaf=15, \n",
    "#                                    min_samples_split=5, \n",
    "#                                    max_depth= 50, \n",
    "#                                    class_weight='balanced_subsample',\n",
    "                                   random_state=0)\n",
    "                                   ),\n",
    "])\n",
    "rfc = rfc.fit(X_train, Y_train)\n",
    "auc = roc_auc_score(Y_test, rfc.predict_proba(X_test)[:, 1])\n",
    "print('Test ROC AUC: %.3f' %auc)\n",
    "predicted = rfc.predict(X_test)\n",
    "print(metrics.classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameter tuning\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000)),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', RandomForestClassifier(n_jobs=-1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__max_depth': [100, 200, 300],\n",
      " 'clf__min_samples_leaf': [20, 50, 80],\n",
      " 'clf__n_estimators': [300, 500, 700]}\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "           \"clf__n_estimators\" : [300, 500, 700],\n",
    "           \"clf__max_depth\" : [100, 200, 300],\n",
    "           \"clf__min_samples_leaf\" : [20, 50, 80]}\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs_clf = GridSearchCV(estimator=text_clf, param_grid=param_grid, n_jobs=-1)\n",
    "# gs_clf.fit(train_comments['comment'], train_comments['attack'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.955\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.96      0.99      0.98     20913\n",
      "       True       0.87      0.64      0.74      2265\n",
      "\n",
      "avg / total       0.95      0.96      0.95     23178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_svc = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='word', max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "linear_svc = linear_svc.fit(X_train, Y_train)\n",
    "auc = linear_svc.score(X_test, Y_test)\n",
    "print('Test ROC AUC: %.3f' %auc)\n",
    "predicted = linear_svc.predict(X_test)\n",
    "print(metrics.classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.925\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.96      0.97      0.97     20913\n",
      "       True       0.71      0.64      0.68      2265\n",
      "\n",
      "avg / total       0.94      0.94      0.94     23178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='word', max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', MLPClassifier()),\n",
    "])\n",
    "mlp = mlp.fit(X_train, Y_train)\n",
    "auc = roc_auc_score(Y_test, mlp.predict_proba(X_test)[:, 1])\n",
    "print('Test ROC AUC: %.3f' %auc)\n",
    "predicted = mlp.predict(X_test)\n",
    "print(metrics.classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correctly classify nice comment\n",
    "lr_clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True], dtype=bool)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment\n",
    "lr_clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15717916480915986"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_val_pred = lr_clf.predict_proba(test_comments['comment'])\n",
    "y_val = test_comments.attack\n",
    "log_loss(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = lr_clf.predict(test_comments['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCoaDJKlgOEiSCv8PUS70+9rGD8MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a35f2fe50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0, 1, 4)\n",
    "data = np.vstack([preds, y_val]).T\n",
    "plt.hist(data, bins, alpha=1, label=['predict','real'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " not_attack       0.99      0.94      0.97     21516\n",
      "     attack       0.55      0.91      0.69      1662\n",
      "\n",
      "avg / total       0.96      0.94      0.95     23178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['not_attack', 'attack']\n",
    "print(classification_report(preds, y_val, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20280,   142],\n",
       "       [ 1236,  1520]])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55772859664985908"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision['micro']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras, os, pickle, re, sklearn, string, tensorflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras.layers import Embedding\n",
    "from keras.optimizers import Adadelta\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING\n",
    "MAX_NUM_WORDS  = 15000\n",
    "EMBEDDING_DIM  = 300\n",
    "MAX_SEQ_LENGTH = 200\n",
    "USE_GLOVE      = True\n",
    "USE_W2V        = True\n",
    "\n",
    "# MODEL\n",
    "FILTER_SIZES   = [3,4,5]\n",
    "FEATURE_MAPS   = [10,10,10]\n",
    "DROPOUT_RATE   = 0.5\n",
    "\n",
    "# LEARNING\n",
    "BATCH_SIZE     = 200\n",
    "NB_EPOCHS      = 40\n",
    "RUNS           = 5\n",
    "VAL_SIZE       = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = X_train.tolist()\n",
    "test_docs = X_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text informations:\n",
      "max length: 2500 / min length: 0 / mean length: 40 / limit length: 200\n",
      "vacobulary size: 118977 / limit: 15000\n"
     ]
    }
   ],
   "source": [
    "def max_length(lines):\n",
    "    \"\"\"\n",
    "    Calculate the maximum document length\n",
    "    \"\"\"\n",
    "    return max([len(s.split()) for s in lines])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(docs)\n",
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "length = max_length(docs)\n",
    "word_index = tokenizer.word_index\n",
    "result = [len(x.split()) for x in docs]\n",
    "\n",
    "print('Text informations:')\n",
    "print('max length: %i / min length: %i / mean length: %i / limit length: %i' % (np.max(result),\n",
    "                                                                                np.min(result),\n",
    "                                                                                np.mean(result),\n",
    "                                                                                MAX_SEQ_LENGTH))\n",
    "print('vacobulary size: %i / limit: %i' % (len(word_index), MAX_NUM_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text informations:\n",
      "max length: 2500 / min length: 0 / mean length: 40 / limit length: 200\n",
      "vacobulary size: 118977 / limit: 15000\n"
     ]
    }
   ],
   "source": [
    "test_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "test_tokenizer.fit_on_texts(test_docs)\n",
    "test_sequences = test_tokenizer.texts_to_sequences(test_docs)\n",
    "\n",
    "test_length = max_length(test_docs)\n",
    "test_word_index = tokenizer.word_index\n",
    "test_result = [len(x.split()) for x in test_docs]\n",
    "\n",
    "print('Text informations:')\n",
    "print('max length: %i / min length: %i / mean length: %i / limit length: %i' % (np.max(test_result),\n",
    "                                                                                np.min(test_result),\n",
    "                                                                                np.mean(test_result),\n",
    "                                                                                MAX_SEQ_LENGTH))\n",
    "print('vacobulary size: %i / limit: %i' % (len(test_word_index), MAX_NUM_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding all sequences to same length of `MAX_SEQ_LENGTH`\n",
    "x_train = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH, padding='post')\n",
    "y_train = Y_train.tolist()\n",
    "x_val = pad_sequences(test_sequences, maxlen=MAX_SEQ_LENGTH, padding='post')\n",
    "y_val = Y_test.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glove_embeddings():\n",
    "    print('Pretrained embeddings GloVe is loading...')\n",
    "\n",
    "    embeddings_index = {}\n",
    "    f = open('glove.6B.300d.sample.txt')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors in GloVe embedding' % len(embeddings_index))\n",
    "\n",
    "    embedding_matrix = np.zeros((MAX_NUM_WORDS, EMBEDDING_DIM))\n",
    "\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i >= MAX_NUM_WORDS:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM,\n",
    "                     input_length=MAX_SEQ_LENGTH,\n",
    "                     weights=[embedding_matrix],\n",
    "                     trainable=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_w2v_embeddings():\n",
    "    print('Pretrained embeddings w2v is loading...')\n",
    "    \n",
    "    model = word2vec.Word2Vec.load('w2v_model')\n",
    "    embeddings_index = {}\n",
    "\n",
    "    embedding_matrix = np.zeros((MAX_NUM_WORDS, EMBEDDING_DIM))\n",
    "\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i >= MAX_NUM_WORDS:\n",
    "            continue\n",
    "        if word in model.wv:\n",
    "            embedding_vector = model.wv[word]\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        #if embedding_vector is not None:\n",
    "            \n",
    "\n",
    "    return Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM,\n",
    "                     input_length=MAX_SEQ_LENGTH,\n",
    "                     weights=[embedding_matrix],\n",
    "                     trainable=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2093, 2727,  670, ...,  524, 1148,  697],\n",
       "       [ 280,  762, 1982, ...,    0,    0,    0],\n",
       "       [ 266,  418,  843, ...,    0,    0,    0],\n",
       "       ..., \n",
       "       [  40,    9,  517, ...,    0,    0,    0],\n",
       "       [  46,   36,   76, ...,    0,    0,    0],\n",
       "       [4174, 2330,  292, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = Y_train.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69526\n",
      "23178\n",
      "69526\n",
      "23178\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_val))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iteration 1/5\n",
      "Pretrained embeddings GloVe is loading...\n",
      "Found 100 word vectors in GloVe embedding\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 15000\n",
      "Embedding dim: 300\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 200\n",
      "#############################################\n",
      "Train on 69526 samples, validate on 23178 samples\n",
      "Epoch 1/40\n",
      "  800/69526 [..............................] - ETA: 21:40 - loss: 2.2548 - acc: 0.7700"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-2e1dd98cddd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         callbacks=[ModelCheckpoint('model-%i.h5'%(i+1), monitor='val_loss',\n\u001b[1;32m     37\u001b[0m                                    verbose=1, save_best_only=True, mode='min'),\n\u001b[0;32m---> 38\u001b[0;31m                    \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                   ]\n\u001b[1;32m     40\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cnn_model\n",
    "\n",
    "histories = []\n",
    "\n",
    "for i in range(RUNS):\n",
    "    print('Running iteration %i/%i' % (i+1, RUNS))\n",
    "    \n",
    "#     x_train, x_val, y_train, y_val = train_test_split(data, label, test_size=VAL_SIZE, random_state=42)\n",
    "    \n",
    "    \n",
    "    if USE_W2V:\n",
    "        emb_layer = create_w2v_embeddings()\n",
    "    elif USE_GLOVE:\n",
    "        emb_layer = create_glove_embeddings()\n",
    "    else:\n",
    "    emb_layer = None\n",
    "    \n",
    "    model = cnn_model.build_cnn(\n",
    "        embedding_layer=emb_layer,\n",
    "        num_words=MAX_NUM_WORDS,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        filter_sizes=FILTER_SIZES,\n",
    "        feature_maps=FEATURE_MAPS,\n",
    "        max_seq_length=MAX_SEQ_LENGTH,\n",
    "        dropout_rate=DROPOUT_RATE\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adadelta(clipvalue=3),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=NB_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "        callbacks=[ModelCheckpoint('model-%i.h5'%(i+1), monitor='val_loss',\n",
    "                                   verbose=1, save_best_only=True, mode='min'),\n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, min_lr=0.01)\n",
    "                  ]\n",
    "    )\n",
    "    print()\n",
    "    histories.append(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69526\n",
      "23178\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
